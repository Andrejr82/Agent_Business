# üöÄ Configura√ß√£o do Google Gemini API

## üìã Resumo

O projeto Ca√ßulinha BI agora suporta m√∫ltiplos provedores de LLM (Large Language Models). Neste guia, voc√™ aprender√° a configurar e usar o **Google Gemini** como provedor LLM principal.

---

## üîß Pr√©-requisitos

1. **Conta Google** - Necess√°ria para acessar Google AI Studio
2. **Chave API do Gemini** - Gratuita na maioria dos casos
3. **Python 3.9+** - Vers√£o recomendada
4. **Acesso ao projeto** - Arquivo `.env` pronto

---

## üìù Passo 1: Obter Chave API do Gemini

### 1.1 Acessar Google AI Studio

1. Visite: **https://aistudio.google.com/app/apikey**
2. Fa√ßa login com sua conta Google
3. Clique em "Create API Key" ‚Üí "Create API key in new project"

### 1.2 Copiar a Chave

- A chave ser√° exibida em tela (ex: `AIza...`)
- ‚ö†Ô∏è **N√ÉO compartilhe** esta chave
- Guarde-a com seguran√ßa

---

## ‚öôÔ∏è Passo 2: Configurar o Projeto

### 2.1 Atualizar Arquivo `.env`

Edite o arquivo `.env` na raiz do projeto:

```env
# ===========================
# LLM Provider Selection
# ===========================

# Selecione o provedor (gemini)
LLM_PROVIDER=gemini

# ===========================
# Gemini Configuration
# ===========================

GEMINI_API_KEY=sua-chave-api-aqui
GEMINI_MODEL_NAME=gemini-pro
```

### 2.2 Instalar Depend√™ncias

```bash
# Se ainda n√£o instalou
pip install -r requirements.txt

# Ou instale apenas o Gemini
pip install google-generativeai>=0.7.0
```

---

## üß™ Passo 3: Testar a Configura√ß√£o

### 3.1 Verificar Disponibilidade

Execute este script Python:

```python
from core.llm_factory import LLMFactory

# Verificar provedores dispon√≠veis
providers = LLMFactory.get_available_providers()
print("Provedores dispon√≠veis:", providers)

# Tentar obter adaptador
try:
    adapter = LLMFactory.get_adapter()
    print(f"‚úÖ Adaptador inicializado: {type(adapter).__name__}")
except Exception as e:
    print(f"‚ùå Erro: {e}")
```

### 3.2 Teste Simples

```python
from core.llm_factory import LLMFactory

adapter = LLMFactory.get_adapter()

messages = [
    {"role": "user", "content": "Ol√°! Quem voc√™ √©?"}
]

response = adapter.get_completion(messages)
print(response)
```

---

## üöÄ Iniciar a Aplica√ß√£o

### Com Streamlit:

```bash
streamlit run streamlit_app.py
```

### Com FastAPI:

```bash
python core/main.py
# ou
uvicorn core.main:app --reload
```

---

## üìä Modelos Dispon√≠veis

| Modelo | Descri√ß√£o | Gratuito |
|--------|-----------|----------|
| `gemini-pro` | Modelo vers√°til de prop√≥sito geral | ‚úÖ Sim |
| `gemini-pro-vision` | Com suporte a imagens | ‚úÖ Sim |
| `gemini-1.5-pro` | Modelo mais avan√ßado | ‚ö†Ô∏è Limitado |

**Altere em `.env`:**

```env
GEMINI_MODEL_NAME=gemini-pro-vision
```

---

## üîÑ Alternar Entre Provedores

### De OpenAI para Gemini:

```env
LLM_PROVIDER=gemini
GEMINI_API_KEY=sua-chave-api-aqui
```

---

## ‚ö†Ô∏è Solu√ß√£o de Problemas

### ‚ùå Erro: "GEMINI_API_KEY n√£o configurada"

**Solu√ß√£o:**
1. Verifique se `.env` existe na raiz do projeto
2. Confirme que `GEMINI_API_KEY` est√° preenchida (n√£o vazia)
3. Reinicie a aplica√ß√£o

### ‚ùå Erro: "google-generativeai n√£o est√° instalado"

**Solu√ß√£o:**
```bash
pip install google-generativeai>=0.7.0
```

### ‚ùå Erro: "API Key inv√°lida ou expirada"

**Solu√ß√£o:**
1. Visite https://aistudio.google.com/app/apikey
2. Regenere a chave
3. Atualize em `.env`

### ‚ùå Aplica√ß√£o carregando lentamente

**Poss√≠vel causa:** Primeiro uso do Gemini (modelo sendo baixado)

**Solu√ß√£o:**
- Aguarde a primeira inicializa√ß√£o
- Use `GEMINI_MODEL_NAME=gemini-pro` (padr√£o, mais r√°pido)

---

## üìà Limites e Quotas

### Gemini API (Gratuito):

- **Requisi√ß√µes por minuto (RPM):** 60
- **Tokens por minuto (TPM):** 1.000.000 (1M)
- **Requisi√ß√µes por dia:** Ilimitado

### Para Produ√ß√£o:

1. Considere plano pago para maior quota
2. Implemente rate limiting na aplica√ß√£o
3. Monitore uso em https://console.cloud.google.com

---

## üîê Seguran√ßa

### ‚úÖ Boas Pr√°ticas:

- ‚úÖ Nunca commite `.env` com chaves reais
- ‚úÖ Use `.env.example` como template
- ‚úÖ Armazene chaves em secrets manager (prod)
- ‚úÖ Rode aplica√ß√£o com permiss√µes m√≠nimas

### üìÅ Exemplo `.gitignore`:

```
.env
.env.local
*.pem
*.key
```

---

## üìö Refer√™ncias

- [Google AI Studio](https://aistudio.google.com)
- [Documenta√ß√£o Gemini API](https://ai.google.dev/tutorials)
- [Google Generative AI Python SDK](https://github.com/google/generative-ai-python)

---

## üí° Dicas √öteis

### 1. Usar Fallback Autom√°tico

Se quiser fallback autom√°tico (Gemini):

```python
# Em core/llm_factory.py, o factory j√° implementa isso
adapter = LLMFactory.get_adapter()
# Tenta Gemini primeiro
```

### 2. Monitorar Uso

```python
from core.config.config import Config

print(f"Provider: {Config().LLM_PROVIDER}")
print(f"Modelo: {Config().GEMINI_MODEL_NAME}")
```

### 3. Testar com Curl

```bash
# Se implementar endpoint FastAPI
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Ol√°", "provider": "gemini"}'
```

---

## ‚úÖ Checklist de Configura√ß√£o

- [ ] Chave API obtida em https://aistudio.google.com/app/apikey
- [ ] `.env` atualizado com `GEMINI_API_KEY`
- [ ] `LLM_PROVIDER=gemini` configurado
- [ ] `google-generativeai` instalado (`pip install -r requirements.txt`)
- [ ] Aplica√ß√£o testada e funcionando
- [ ] Logging visualizado (DEBUG mode para mais detalhe)
- [ ] `.env` n√£o commitado no Git

---

**Status:** ‚úÖ Gemini configurado e pronto para uso!