# âš¡ Guia RÃ¡pido - Gemini LLM Setup

> **TL;DR** (Too Long; Didn't Read): Tudo jÃ¡ estÃ¡ configurado. Teste com `python scripts/test_llm_setup.py` e use!

---

## ğŸ¯ Em 60 Segundos

```bash
# 1. Validar setup (30 segundos)
python scripts/test_llm_setup.py

# 2. Iniciar app (10 segundos)
streamlit run streamlit_app.py

# 3. Testar no chat (20 segundos)
# â†’ Digite: "OlÃ¡!"
# â†’ Resposta vem do Gemini âœ…
```

**Pronto!** A configuraÃ§Ã£o estÃ¡ funcionando.

---

## âœ… O Que EstÃ¡ Pronto

- âœ… **Adaptador Gemini** - `core/llm_gemini_adapter.py`
- âœ… **Factory LLM** - `core/llm_factory.py`
- âœ… **ConfiguraÃ§Ãµes** - `core/config/config.py` atualizado
- âœ… **Chaves de API** - `.env` preenchido (Gemini)
- âœ… **DocumentaÃ§Ã£o** - 5 documentos completos
- âœ… **Testes** - Script automatizado pronto
- âœ… **DependÃªncias** - `google-generativeai` adicionado

---

## ğŸ“‹ VariÃ¡veis de Ambiente

```env
# Ativo agora
LLM_PROVIDER=gemini
GEMINI_API_KEY=AIzaSyAVslwdt_g_ChwaonlHkCvn_KZ9RmddtYs
```

---

## ğŸ”„ No CÃ³digo

```python
# Sempre funciona assim (automÃ¡tico)
from core.llm_factory import LLMFactory

adapter = LLMFactory.get_adapter()  # Usa .env (LLM_PROVIDER)
response = adapter.get_completion(messages)
print(response)
```

---

## ğŸ†˜ Problemas Comuns

| Problema | SoluÃ§Ã£o |
|----------|---------|
| Teste falha | `python scripts/test_llm_setup.py` para debug |
| MÃ³dulo nÃ£o encontrado | `pip install -r requirements.txt` |
| App lenta | Normal 1Âª vez (30-60s) |

---

## ğŸ“š DocumentaÃ§Ã£o

**NÃ£o sabe por onde comeÃ§ar?**

- ğŸ‘‰ **RÃ¡pido:** [RESUMO_VISUAL_GEMINI.txt](RESUMO_VISUAL_GEMINI.txt)
- ğŸ‘‰ **MÃ©dio:** [RESUMO_CONFIGURACAO_GEMINI.md](RESUMO_CONFIGURACAO_GEMINI.md)
- ğŸ‘‰ **Completo:** [CONFIGURACAO_GEMINI.md](CONFIGURACAO_GEMINI.md)
- ğŸ‘‰ **TÃ©cnico:** [RELATORIO_IMPLEMENTACAO_GEMINI.md](RELATORIO_IMPLEMENTACAO_GEMINI.md)
- ğŸ‘‰ **Ãndice:** [INDICE_GEMINI.md](INDICE_GEMINI.md)

---

## ğŸš€ ComeÃ§ar Agora

```bash
# Terminal Windows (PowerShell)
python scripts/test_llm_setup.py
streamlit run streamlit_app.py

# Terminal Mac/Linux
python3 scripts/test_llm_setup.py
streamlit run streamlit_app.py
```

---

## âœ¨ PrÃ³ximas Melhorias (Opcional)

- [ ] Cache de respostas
- [ ] Dashboard de monitoramento
- [ ] Mais provedores (DeepSeek, Claude)
- [ ] Rate limiting
- [ ] MÃ©tricas

---

**Status:** âœ… **PRONTO PARA USAR**

**Data:** 14 de novembro de 2025